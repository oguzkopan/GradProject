{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5092f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 16:36:21.345423: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import ta\n",
    "from binance.client import Client\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Just disables the warning, doesn't take advantage of AVX/FMA to run faster\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model \n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "import math\n",
    "import pywt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy.signal import butter, lfilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70c9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing averages\n",
    "def yy5(input_data):\n",
    "    A=0\n",
    "    B=0\n",
    "    C=0\n",
    "    D=0\n",
    "    outputavg = []    \n",
    "    for X in input_data:\n",
    "        Y=(X+A+B+C+D)/5\n",
    "        outputavg.append(Y)\n",
    "        D=C\n",
    "        C=B\n",
    "        B=A\n",
    "        A=X\n",
    "\n",
    "    return outputavg\n",
    "\n",
    "\n",
    "#construction of outputs\n",
    "def output(inputdata):\n",
    "    out=[]\n",
    "    for i in range(7, len(inputdata)-1):\n",
    "        out.append(inputdata[i+1])\n",
    "    out = np.append(out, [np.nan])\n",
    "    return out\n",
    "\n",
    "#successive values \n",
    "def successive(successive):\n",
    "\n",
    "    input_data=[]\n",
    "    for i in range(7, len(successive)):\n",
    "\n",
    "        input_data.append([successive[i-3]]+[successive[i-2]]+[successive[i-1]]+[successive[i]])\n",
    "    return input_data  \n",
    "\n",
    "#wavelet transform\n",
    "def four_wavelets(training):\n",
    "    input_data=np.array(training)\n",
    "    days = input_data[:,0:4]\n",
    "\n",
    "\n",
    "    for row in input_data:\n",
    "            (a, d) = pywt.dwt(days, 'haar')\n",
    "            (a2,d2)=pywt.dwt(a, 'haar') \n",
    "            l3=np.append(a2,d2, axis=1)\n",
    "            l2_3=np.append(l3,d, axis=1)\n",
    "            transformed_df=l2_3\n",
    "\n",
    "    training=transformed_df\n",
    "\n",
    "\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567296f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pecnet():\n",
    "    #network configurations\n",
    "    hidden1=32\n",
    "    second_layer1=32\n",
    "    third_layer1=32\n",
    "    forth_layer1=16\n",
    "    hidden2=32\n",
    "    second_layer2=32\n",
    "    third_layer2=32\n",
    "    forth_layer2=16\n",
    "    hidden3=32\n",
    "    second_layer3=32\n",
    "    third_layer3=32\n",
    "    forth_layer3=16\n",
    "    hidden4=32\n",
    "    second_layer4=32\n",
    "    third_layer4=32\n",
    "    forth_layer4=16\n",
    "    hidden5=32\n",
    "    second_layer5=32\n",
    "    third_layer5=32\n",
    "    forth_layer5=16\n",
    "\n",
    "\n",
    "\n",
    "    #calling input files\n",
    "    #input_data=pd.read_csv('bistclose.csv')\n",
    "    #input_data=pd.read_csv('close_is.csv')\n",
    "    #input_data=pd.read_csv('open.csv')\n",
    "    #input_data=pd.read_csv('close.csv')\n",
    "    #input_data=pd.read_csv('min.csv')\n",
    "    #input_data=pd.read_csv('max.csv')\n",
    "    input_data=pd.read_csv('file2.csv')\n",
    "\n",
    "\n",
    "    #construction of input arrays\n",
    "    input_data=np.array(input_data)\n",
    "    input_data=input_data.reshape(input_data.shape[0])\n",
    "    input_data=list(input_data)\n",
    "    input_data=np.array(input_data)\n",
    "\n",
    "\n",
    "    average=yy5(input_data)\n",
    "    input_data_average=successive(average)\n",
    "    input_data_successive=successive(input_data)\n",
    "    out=output(input_data)\n",
    "    \n",
    "    #%matplotlib notebook\n",
    "\n",
    "    #fig,ax= plt.subplots()\n",
    "    #ax.plot(input_data, label='daily_input')\n",
    "    #ax.plot(average, label='average_input')\n",
    "    #ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.00), shadow=True, ncol=2)\n",
    "    #plt.title('Input data')\n",
    "    #plt.show();\n",
    "\n",
    "\n",
    "    #division of data set into training and test data set\n",
    "    N=len(input_data)\n",
    "    division_of_training=0.98\n",
    "    input_train=input_data_average[:int(N*division_of_training)]\n",
    "    input_test=input_data_average[int(N*division_of_training):int(N*1)]\n",
    "\n",
    "    successive_train=input_data_successive[:int(N*division_of_training)]\n",
    "    successive_test=input_data_successive[int(N*division_of_training):int(N*1)]\n",
    "\n",
    "    second_input_train=successive_train \n",
    "    second_input_test=successive_test \n",
    "\n",
    "    output_train= out[:int(N*division_of_training)]\n",
    "    output_test=out[int(N*division_of_training):int(N*1)]\n",
    "\n",
    "\n",
    "\n",
    "    #normalization\n",
    "    inputiavg=np.array(input_train)\n",
    "    inputiavgt=np.array(input_test)\n",
    "\n",
    "    inputsuc=np.array(second_input_train)\n",
    "    inputsuct=np.array(second_input_test)\n",
    "\n",
    "    subtraction_average_train=inputiavg\n",
    "    subtraction_average_test=inputiavgt\n",
    "\n",
    "    subtraction_successive_train=inputsuc\n",
    "    subtraction_successive_test=inputsuct\n",
    "\n",
    "    subtraction_average_train=subtraction_average_train.sum(axis=1)/4\n",
    "    subtraction_average_test=subtraction_average_test.sum(axis=1)/4\n",
    "\n",
    "    subtraction_successive_train=subtraction_successive_train.sum(axis=1)/4\n",
    "    subtraction_successive_test=subtraction_successive_test.sum(axis=1)/4\n",
    "\n",
    "    #normalization of inputs\n",
    "    first_input_train=input_train-subtraction_average_train[:, None]\n",
    "    first_input_test=input_test-subtraction_average_test[:,None]\n",
    "\n",
    "    output_train=output_train-subtraction_successive_train\n",
    "    output_test=output_test-subtraction_successive_test\n",
    "\n",
    "    second_input_train=second_input_train-subtraction_successive_train[:,None]\n",
    "    second_input_test=second_input_test-subtraction_successive_test[:,None]\n",
    "\n",
    "\n",
    "    #4inputs WT\n",
    "    final_first_w_input_train=four_wavelets(first_input_train)\n",
    "    final_first_w_input_test=four_wavelets(first_input_test)\n",
    "\n",
    "    X_train=np.array(final_first_w_input_train[:, 1:])\n",
    "    y_train=np.array(output_train)\n",
    "\n",
    "    X_test=np.array(final_first_w_input_test[:,1:])\n",
    "    y_test=np.array(output_test)\n",
    "\n",
    "    m_primary=len(X_train[0,:])\n",
    "    p_primary=np.size(y_train[0])\n",
    "    N_primary=len(X_train)\n",
    "\n",
    "    model= Sequential ([\n",
    "        Dense(hidden1, input_dim=m_primary, activation='relu'), \n",
    "        Dropout(0.1),\n",
    "        Dense(second_layer1), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(third_layer1), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(forth_layer1), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(p_primary)\n",
    "        ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    sgd=SGD(learning_rate=0.05,momentum=0.75, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mean_absolute_error','mean_squared_logarithmic_error','cosine_similarity','logcosh'])\n",
    "    history1=model.fit(X_train, y_train, batch_size=N_primary, epochs=300, shuffle=False, verbose=0)  \n",
    "\n",
    "    predicted_train = model.predict(X_train) \n",
    "    predicted_train = np.reshape(predicted_train, (predicted_train.size,))\n",
    "    error_train1=predicted_train-y_train\n",
    "\n",
    "    predicted_test = model.predict(X_test) \n",
    "    predicted_test = np.reshape(predicted_test, (predicted_test.size,))\n",
    "    error_test1=predicted_test-y_test\n",
    "\n",
    "\n",
    "    # Second NN, error forecasting network \n",
    "    error_train=pd.DataFrame(error_train1)\n",
    "    add_train=four_wavelets(second_input_train) \n",
    "\n",
    "    X_error_train1=np.array(add_train[:, 1:])\n",
    "    y_error_train1=np.array(error_train)\n",
    "\n",
    "    error_test=pd.DataFrame(error_test1)\n",
    "    add_test=four_wavelets(second_input_test) \n",
    "\n",
    "    X_error_test1=np.array(add_test[:, 1:])\n",
    "\n",
    "    m_second=len(X_error_train1[0,:])\n",
    "    p_second=np.size(y_train[0])\n",
    "    N_second=len(X_error_train1)\n",
    "\n",
    "    error_model1= Sequential ([\n",
    "        Dense(hidden2, input_dim=m_second, activation='relu'), \n",
    "        Dropout(0.1),\n",
    "        Dense(second_layer2), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(third_layer2), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(forth_layer2), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(p_second)\n",
    "    ])\n",
    "\n",
    "    error_model1.summary()\n",
    "\n",
    "    sgd=SGD(learning_rate=0.05, momentum=0.75, decay=0.0, nesterov=False)\n",
    "    error_model1.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse','mae','accuracy'])\n",
    "    history3=error_model1.fit(X_error_train1, y_error_train1, batch_size=N_second, epochs=300, shuffle=False, verbose=0)\n",
    "\n",
    "    error_predicted_tr = error_model1.predict(X_error_train1)\n",
    "    error_predicted_tr = np.reshape(error_predicted_tr, (error_predicted_tr.size,))\n",
    "    error_predicted_tes = error_model1.predict(X_error_test1)\n",
    "    error_predicted_tes = np.reshape(error_predicted_tes, (error_predicted_tes.size,))\n",
    "\n",
    "    compensated1_train=(predicted_train+subtraction_successive_train)-(error_predicted_tr)\n",
    "    compensated1_test=(predicted_test+subtraction_successive_test)-(error_predicted_tes)\n",
    "\n",
    "\n",
    "    # Third NN, error network \n",
    "    error_train2a=compensated1_train-(y_train+subtraction_successive_train)\n",
    "    error_test2a=compensated1_test-(y_test+subtraction_successive_test)\n",
    "\n",
    "    error_train2=pd.DataFrame(error_train2a)\n",
    "    error_train2 [1]= error_train2[0].shift(1)\n",
    "    error_train2 [2]=error_train2[1].shift(1)\n",
    "    error_train2 [3]=error_train2[2].shift(1)\n",
    "    error_train2[4]=error_train2[3].shift(1)\n",
    "    error_train2 = error_train2.replace(np.nan, 0)\n",
    "\n",
    "    ##error normalization\n",
    "    subtraction_error_train2=np.array(error_train2)\n",
    "    subtraction_error_train2=subtraction_error_train2[:,:-1]\n",
    "    subtraction_error_train2=subtraction_error_train2.sum(axis=1)/4\n",
    "\n",
    "    error_train2=error_train2-subtraction_error_train2[:, None]\n",
    "\n",
    "\n",
    "    error_train2=np.array(error_train2)\n",
    "    days_train = error_train2[:,1:5]\n",
    "    input3_train=four_wavelets(days_train)\n",
    "    output3_train=error_train2[:,0:1]\n",
    "\n",
    "    X_error_train2=np.array(input3_train[:, 1:])\n",
    "    y_error_train2=np.array(output3_train)\n",
    "\n",
    "    error_test2=pd.DataFrame(error_test2a)\n",
    "    error_test2 [1]= error_test2[0].shift(1)\n",
    "    error_test2 [2]=error_test2[1].shift(1)\n",
    "    error_test2 [3]=error_test2[2].shift(1)\n",
    "    error_test2[4]=error_test2[3].shift(1)\n",
    "    error_test2 = error_test2.replace(np.nan, 0)\n",
    "\n",
    "    subtraction_error_test2=np.array(error_test2)\n",
    "    subtraction_error_test2=subtraction_error_test2[:,:-1]\n",
    "    subtraction_error_test2=subtraction_error_test2.sum(axis=1)/4\n",
    "\n",
    "    error_test2=error_test2-subtraction_error_test2[:,None]\n",
    "\n",
    "    error_test2=np.array(error_test2)\n",
    "    days_test = error_test2[:,1:5]\n",
    "    input3_test=four_wavelets(days_test)\n",
    "    output3_test=error_test2[:,0:1]\n",
    "\n",
    "    X_error_test2=np.array(input3_test[:, 1:])\n",
    "\n",
    "\n",
    "    #####3rd NN\n",
    "    m_error=len(X_error_train2[0,:])\n",
    "    p_error=np.size(y_error_train2[0])\n",
    "    N_error=len(X_error_train2)\n",
    "\n",
    "\n",
    "\n",
    "    error_model2= Sequential ([\n",
    "        Dense(hidden3, input_dim=m_error, activation='relu'), \n",
    "        Dropout(0.1),\n",
    "        Dense(second_layer3), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(third_layer3), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(forth_layer3), #,activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(p_error)\n",
    "    ])\n",
    "\n",
    "    error_model2.summary()\n",
    "\n",
    "    sgd=SGD(learning_rate=0.05, momentum=0.75, decay=0.0, nesterov=False)\n",
    "    error_model2.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse','mae','accuracy'])\n",
    "    history4=error_model2.fit(X_error_train2, y_error_train2, batch_size=N_error, epochs=300, shuffle=False, verbose=0)\n",
    "\n",
    "\n",
    "    error_predicted_tr2 = error_model2.predict(X_error_train2)\n",
    "    error_predicted_tr2 = np.reshape(error_predicted_tr2, (error_predicted_tr2.size,))\n",
    "    error_predicted_tes2 = error_model2.predict( X_error_test2)\n",
    "    error_predicted_tes2= np.reshape(error_predicted_tes2, (error_predicted_tes2.size,))\n",
    "\n",
    "    compensated_y_train=compensated1_train-(error_predicted_tr2+subtraction_error_train2)\n",
    "    compensated_y_test=compensated1_test-(error_predicted_tes2+subtraction_error_test2)\n",
    "\n",
    "\n",
    "    # Final NN \n",
    "    error_predicted_tr3=error_predicted_tr2+subtraction_error_train2\n",
    "    error_predicted_tes3=error_predicted_tes2+subtraction_error_test2\n",
    "\n",
    "    training_final_add=np.column_stack((predicted_train, error_predicted_tr))\n",
    "    training_final_add=np.column_stack((training_final_add,error_predicted_tr3))\n",
    "\n",
    "    test_final_add=np.column_stack((predicted_test, error_predicted_tes))\n",
    "    test_final_add=np.column_stack((test_final_add,error_predicted_tes3))\n",
    "\n",
    "    ####final NN\n",
    "    m_final=len(training_final_add[0,:])\n",
    "    p_final=np.size(y_train[0])\n",
    "    N_final=len(training_final_add)\n",
    "\n",
    "    final_model= Sequential ([\n",
    "        Dense(hidden4, input_dim=m_final, activation='relu'), \n",
    "    #    Dropout(0.1),\n",
    "    #    Dense(second_layer4), #,activation='relu'),\n",
    "    #    Dropout(0.1),\n",
    "    #    Dense(third_layer4), #,activation='relu'),\n",
    "    #    Dropout(0.1),\n",
    "    #    Dense(forth_layer4), #,activation='relu'),\n",
    "    #    Dropout(0.1),\n",
    "        Dense(p_final)\n",
    "    ])\n",
    "\n",
    "    final_model.summary()\n",
    "\n",
    "    sgd=SGD(learning_rate=0.05, momentum=0.75, decay=0.0, nesterov=False)\n",
    "    final_model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse','mae','accuracy'])\n",
    "    final_history=final_model.fit(training_final_add, y_train, batch_size=N_final, epochs=300, shuffle=False, verbose=0)\n",
    "\n",
    "\n",
    "    final_predicted_tr =final_model.predict(training_final_add)\n",
    "    final_predicted_tr = np.reshape(final_predicted_tr, (final_predicted_tr.size,))\n",
    "    final_predicted_tes = final_model.predict(test_final_add)\n",
    "    final_predicted_tes = np.reshape(final_predicted_tes, (final_predicted_tes.size,))\n",
    "\n",
    "\n",
    "\n",
    "    # errors\n",
    "    EPSILON =  1e-10\n",
    "\n",
    "    y_train=y_train+subtraction_successive_train\n",
    "    final_y_train=final_predicted_tr+subtraction_successive_train\n",
    "    final_y_train = np.reshape(final_y_train, (final_y_train.size,))\n",
    "\n",
    "    final_error_train=final_y_train-y_train\n",
    "    final_rmse_error_train=np.sqrt(sum(final_error_train*final_error_train)/len(final_error_train))\n",
    "    final_mse_train=(sum(final_error_train*final_error_train)/len(final_error_train))\n",
    "    final_mape_train=100*sum(abs(final_error_train/y_train))/len(y_train)\n",
    "    final_mae_train=sum(abs(final_error_train-y_train))/len(y_train)\n",
    "    final_rmspe_train=100*np.sqrt(np.nanmean(np.square(((y_train - final_y_train) / (y_train+ EPSILON)))))\n",
    "\n",
    "\n",
    "    y_test=y_test+subtraction_successive_test\n",
    "\n",
    "    final_y_test=final_predicted_tes+subtraction_successive_test\n",
    "    y_test = np.reshape(y_test, (y_test.size,))\n",
    "    final_y_test = np.reshape(final_y_test, (final_y_test.size,))\n",
    "\n",
    "\n",
    "    #final_error_test=y_test[:-1]-final_predicted_tes[:-1]\n",
    "    final_error_test=final_y_test[:-1]-y_test[:-1] \n",
    "    final_rmse_error_test=np.sqrt(sum(final_error_test*final_error_test)/len(final_error_test))\n",
    "    final_mse_test=(sum(final_error_test*final_error_test)/len(final_error_test))\n",
    "    final_mape_test=100*sum(abs(final_error_test/y_test[:-1]))/len(y_test-1)\n",
    "    final_mae_test=sum(abs(final_error_test-y_test[:-1]))/len(y_test-1)\n",
    "    final_rmspe_test=100*np.sqrt(np.nanmean(np.square(((y_test[:-1] - final_y_test[:-1]) / (y_test[:-1]+ EPSILON)))))\n",
    "\n",
    "    #errors of the first nn\n",
    "    predicted_train=predicted_train+subtraction_successive_train\n",
    "    predicted_test=predicted_test+subtraction_successive_test\n",
    "\n",
    "    predicted_error_train=predicted_train-y_train\n",
    "    predicted_rmse_error_train=np.sqrt(sum(predicted_error_train*predicted_error_train)/len(predicted_error_train))\n",
    "    predicted_mse_train=(sum(predicted_error_train*predicted_error_train)/len(predicted_error_train))\n",
    "    predicted_mape_train=100*sum(abs(predicted_error_train/y_train))/len(y_train)\n",
    "    predicted_mae_train=sum(abs(predicted_error_train-y_train))/len(y_train)\n",
    "    predicted_rmspe_train=100*np.sqrt(np.nanmean(np.square(((y_train - predicted_train) /(y_train+ EPSILON)))))\n",
    "\n",
    "    predicted_error_test=predicted_test[:-1]-y_test[:-1]\n",
    "    predicted_rmse_error_test=np.sqrt(sum(predicted_error_test*predicted_error_test)/len(predicted_error_test))\n",
    "    predicted_mse_test=(sum(predicted_error_test*predicted_error_test)/len(predicted_error_test))\n",
    "    predicted_mape_test=100*sum(abs(predicted_error_test/y_test[:-1]))/len(y_test-1)\n",
    "    predicted_mae_test=sum(abs(predicted_error_test-y_test[:-1]))/len(y_test-1)\n",
    "    predicted_rmspe_test=100*np.sqrt(np.nanmean(np.square(((y_test[:-1] - predicted_test[:-1]) / (y_test[:-1]+ EPSILON)))))\n",
    "\n",
    "    #errors of the second nn\n",
    "    compensated1_train_error=compensated1_train-y_train\n",
    "\n",
    "    compensated1_train_rmse_error_train=np.sqrt(sum(compensated1_train_error*compensated1_train_error)/len(compensated1_train_error))\n",
    "    compensated1_train_mse_train=(sum(compensated1_train_error*compensated1_train_error)/len(compensated1_train_error))\n",
    "    compensated1_train_mape_train=100*sum(abs(compensated1_train_error/y_train))/len(y_train)\n",
    "    compensated1_train_mae_train=sum(abs(compensated1_train_error-y_train))/len(y_train)\n",
    "    compensated1_train_rmspe_train=np.sqrt(np.nanmean(np.square(((y_train - compensated1_train) /(y_train+ EPSILON)))))*100\n",
    "\n",
    "    compensated1_test_error=compensated1_test[:-1]-y_test[:-1]\n",
    "\n",
    "    compensated1_test_rmse_error_test=np.sqrt(sum(compensated1_test_error*compensated1_test_error)/len(compensated1_test_error))\n",
    "    compensated1_test_mse_test=(sum(compensated1_test_error*compensated1_test_error)/len(compensated1_test_error))\n",
    "    compensated1_test_mape_test=100*sum(abs(compensated1_test_error/y_test[:-1]))/len(y_test-1)\n",
    "    compensated1_test_mae_test=sum(abs(compensated1_test_error-y_test[:-1]))/len(y_test-1)\n",
    "    compensated1_test_rmspe_test=np.sqrt(np.nanmean(np.square(((y_test[:-1] - compensated1_test[:-1]) / (y_test[:-1]+ EPSILON)))))*100\n",
    "\n",
    "    #errors of the third nn\n",
    "    compensated_error_train=compensated_y_train-y_train\n",
    "\n",
    "    comp_rmse_error_train=np.sqrt(sum(compensated_error_train*compensated_error_train)/len(compensated_error_train))\n",
    "    comp_mse_train=(sum(compensated_error_train*compensated_error_train)/len(compensated_error_train))\n",
    "    comp_mape_train=100*sum(abs(compensated_error_train/y_train))/len(y_train)\n",
    "    comp_mae_train=sum(abs(compensated_error_train-y_train))/len(y_train)\n",
    "    comp_rmspe_train=np.sqrt(np.nanmean(np.square(((y_train - compensated_y_train) / (y_train+ EPSILON)))))*100\n",
    "\n",
    "    compensated_error_test=compensated_y_test[:-1]-y_test[:-1]\n",
    "\n",
    "    comp_rmse_error_test=np.sqrt(sum(compensated_error_test*compensated_error_test)/len(compensated_error_test))\n",
    "    comp_mse_test=(sum(compensated_error_test*compensated_error_test)/len(compensated_error_test))\n",
    "    comp_mape_test=100*sum(abs(compensated_error_test/y_test[:-1]))/len(y_test-1)\n",
    "    comp_mae_test=sum(abs(compensated_error_test-y_test[:-1]))/len(y_test-1)\n",
    "    comp_rmspe_test=np.sqrt(np.nanmean(np.square(((y_test[:-1] - compensated_y_test[:-1]) / (y_test[:-1]+ EPSILON)))))*100\n",
    "\n",
    "    zz_rmse_errors_ttrain=(predicted_rmse_error_train,compensated1_train_rmse_error_train, comp_rmse_error_train,final_rmse_error_train)\n",
    "    zz_rmse_errors_test=(predicted_rmse_error_test,compensated1_test_rmse_error_test, comp_rmse_error_test,final_rmse_error_test)\n",
    "\n",
    "    zz_rmspe_errors_ttrain=(predicted_rmspe_train,compensated1_train_rmspe_train, comp_rmspe_train,final_rmspe_train)\n",
    "    zz_rmspe_errors_test=(predicted_rmspe_test,compensated1_test_rmspe_test, comp_rmspe_test,final_rmspe_test)\n",
    "\n",
    "    zz_mape_errors_ttrain=(predicted_mape_train,compensated1_train_mape_train, comp_mape_train,final_mape_train)\n",
    "    zz_mape_errors_test=(predicted_mape_test,compensated1_test_mape_test, comp_mape_test,final_mape_test)\n",
    "\n",
    "    zz_mae_errors_ttrain=(predicted_mae_train,compensated1_train_mae_train, comp_mae_train,final_mae_train)\n",
    "    zz_mae_errors_test=(predicted_mae_test,compensated1_test_mae_test, comp_mae_test,final_mae_test)\n",
    "\n",
    "    zz_predictions_train = (y_train, predicted_train,compensated1_train,  compensated_y_train, final_y_train)\n",
    "    zz_predictions_test = (y_test,predicted_test,compensated1_test, compensated_y_test, final_y_test)\n",
    "    \n",
    "    return y_test, final_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31aca4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeBase():\n",
    "\n",
    "    def __init__(self, symbol, start, end, amount, use_prediction = True):\n",
    "        self.symbol = symbol\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.initial_balance = amount\n",
    "        self.current_balance = amount\n",
    "        self.units = 0\n",
    "        self.trades = 0\n",
    "        self.use_prediction = use_prediction\n",
    "        self.get_data()\n",
    "        self.create_positions()\n",
    "\n",
    "    def create_positions(self):\n",
    "        pos = pd.DataFrame(columns=[\"date\",\"price\",\"pos_changed\",\"current_balance\"])\n",
    "        pos.set_index(\"date\")\n",
    "        self.positions = pos\n",
    "        \n",
    "    def add_position(self, date, price, pos_changed, current_balance):\n",
    "        df_new_row = pd.DataFrame([{ 'date':date,'price':price, 'pos_changed':pos_changed, 'current_balance':current_balance }])\n",
    "        self.positions = pd.concat([self.positions, df_new_row], ignore_index=True)\n",
    "\n",
    "    def get_data(self):\n",
    "        raw = pd.read_csv(\"new.csv\", parse_dates = [\"date\"], index_col = \"date\", engine='python').dropna()\n",
    "        raw = raw.loc[self.start:self.end]\n",
    "        #raw[\"returns\"] = np.log(raw.price / raw.price.shift(1))\n",
    "        self.data = raw\n",
    "\n",
    "    def plot_data(self, cols = None):  \n",
    "        if cols is None:\n",
    "            cols = \"price\"\n",
    "        self.data[cols].plot(figsize = (15, 8), title = self.symbol + \"PRICE\")\n",
    "        #fig = px.line(self.data, x=self.data.index, y=cols, title=\"ISCTR - Close Prices\")  # creating a figure using px.line\n",
    "        #fig.show()\n",
    "    \n",
    "    def get_values(self, bar):\n",
    "        date = str(self.data.index[bar].date())\n",
    "        price = round(self.data.price.iloc[bar], 5)\n",
    "        prediction = round(self.data.pred.iloc[bar], 5)\n",
    "        return date, price, prediction\n",
    "    \n",
    "    def print_current_balance(self, bar):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        print(\"{} | Current Balance: {}\".format(date, round(self.current_balance, 2)))\n",
    "        \n",
    "        \n",
    "    def buy_instrument(self, bar, units = None, amount = None):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        #if self.use_spread:\n",
    "        #    price += spread/2 # ask price\n",
    "        if amount is not None: # use units if units are passed, otherwise calculate units\n",
    "            units = int(amount / price)\n",
    "        self.current_balance -= units * price # reduce cash balance by \"purchase price\"\n",
    "        self.units += units\n",
    "        self.trades += 1\n",
    "        print(\"{} |  Buying {} for {}\".format(date, units, round(price, 5)))\n",
    "    \n",
    "    def sell_instrument(self, bar, units = None, amount = None):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        #if self.use_spread:\n",
    "        #    price -= spread/2 # bid price\n",
    "        if amount is not None: # use units if units are passed, otherwise calculate units\n",
    "            units = int(amount / price)\n",
    "        self.current_balance += units * price # increases cash balance by \"purchase price\"\n",
    "        self.units -= units\n",
    "        self.trades += 1\n",
    "        print(\"{} |  Selling {} for {}\".format(date, units, round(price, 5)))\n",
    "    \n",
    "    def print_current_position_value(self, bar):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        cpv = self.units * price\n",
    "        print(\"{} |  Current Position Value = {}\".format(date, round(cpv, 2)))\n",
    "    \n",
    "    def print_current_nav(self, bar):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        nav = self.current_balance + self.units * price\n",
    "        print(\"{} |  Net Asset Value = {}\".format(date, round(nav, 2)))\n",
    "        \n",
    "    def get_current_nav(self, bar):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        nav = self.current_balance + self.units * price\n",
    "        return round(nav, 2)\n",
    "        \n",
    "    def close_pos(self, bar):\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        print(75 * \"-\")\n",
    "        print(\"{} | +++ CLOSING FINAL POSITION +++\".format(date))\n",
    "        self.current_balance += self.units * price # closing final position (works with short and long!)\n",
    "        #self.current_balance -= (abs(self.units) * spread/2 * self.use_spread) # substract half-spread costs\n",
    "        print(\"{} | closing position of {} for {}\".format(date, self.units, price))\n",
    "        self.units = 0 # setting position to neutral\n",
    "        self.trades += 1\n",
    "        perf = (self.current_balance - self.initial_balance) / self.initial_balance * 100\n",
    "        self.print_current_balance(bar)\n",
    "        print(\"{} | net performance (%) = {}\".format(date, round(perf, 2) ))\n",
    "        print(\"{} | number of trades executed = {}\".format(date, self.trades))\n",
    "        print(75 * \"-\")\n",
    "        \n",
    "    def plot_pnl_price(self):\n",
    "        subfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        # plotting close prices with bollinger bands\n",
    "        fig = px.line(self.positions, x='date', y='current_balance')\n",
    "        fig2 = px.line(self.positions, x='date', y='price')\n",
    "        \n",
    "        fig2.update_traces(yaxis=\"y2\")\n",
    "\n",
    "        # adding trades to plots\n",
    "        for bar in range(len(self.positions)-1):\n",
    "            if self.positions[\"current_balance\"].iloc[bar+1] >= self.positions[\"current_balance\"].iloc[bar]:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"current_balance\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"current_balance\"].iloc[bar+1],\n",
    "                    line=dict(color=\"green\", width=3))\n",
    "            else:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"current_balance\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"current_balance\"].iloc[bar+1],\n",
    "                    line=dict(color=\"red\", width=3))\n",
    "        \n",
    "        subfig.layout.xaxis.title=\"Time\"\n",
    "        subfig.layout.yaxis.title=\"PNL(Balance)\"\n",
    "        subfig.layout.yaxis2.type=\"log\"\n",
    "        subfig.layout.yaxis2.title=\"Price\"\n",
    "        \n",
    "        subfig.add_traces(fig.data + fig2.data)\n",
    "        subfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color)))\n",
    "        subfig.show()\n",
    "        \n",
    "    def plot_pretty_balance(self):\n",
    "        # plotting close prices with bollinger bands\n",
    "        fig = px.line(self.positions, x='date', y='current_balance')\n",
    "\n",
    "        # adding trades to plots\n",
    "        for bar in range(len(self.positions)-1):\n",
    "            if self.positions[\"current_balance\"].iloc[bar+1] >= self.positions[\"current_balance\"].iloc[bar]:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"current_balance\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"current_balance\"].iloc[bar+1],\n",
    "                    line=dict(color=\"green\", width=3))\n",
    "            else:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"current_balance\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"current_balance\"].iloc[bar+1],\n",
    "                    line=dict(color=\"red\", width=3))\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_pretty_price(self):\n",
    "        # plotting close prices with bollinger bands\n",
    "        fig = px.line(self.positions, x='date', y='price')\n",
    "\n",
    "        # adding trades to plots\n",
    "        for bar in range(len(self.positions)-1):\n",
    "            if self.positions[\"current_balance\"].iloc[bar+1] >= self.positions[\"current_balance\"].iloc[bar]:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"price\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"price\"].iloc[bar+1],\n",
    "                    line=dict(color=\"green\", width=3))\n",
    "            else:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"price\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"price\"].iloc[bar+1],\n",
    "                    line=dict(color=\"red\", width=3))\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_prettier(self):\n",
    "        df = pd.read_csv('new.csv')\n",
    "        # plotting close prices with bollinger bands\n",
    "        #print(df)\n",
    "        fig = px.line(df, x='date', y='price')\n",
    "        \n",
    "        # adding trades to plots\n",
    "        for bar in range(len(self.positions)-1):\n",
    "            if self.positions[\"current_balance\"].iloc[bar+1] >= self.positions[\"current_balance\"].iloc[bar]:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"price\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"price\"].iloc[bar+1],\n",
    "                    line=dict(color=\"green\", width=3))\n",
    "            else:\n",
    "                fig.add_shape(type=\"line\",\n",
    "                    x0=self.positions[\"date\"].iloc[bar], y0=self.positions[\"price\"].iloc[bar], x1=self.positions[\"date\"].iloc[bar+1], y1=self.positions[\"price\"].iloc[bar+1],\n",
    "                    line=dict(color=\"red\", width=3))\n",
    "                \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e636cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeBacktest(IterativeBase):\n",
    "\n",
    "    # helper method\n",
    "    def go_long(self, bar, units = None, amount = None):\n",
    "        if self.position == -1:\n",
    "            self.buy_instrument(bar, units = -self.units) # if short position, go neutral first\n",
    "        if units:\n",
    "            self.buy_instrument(bar, units = units)\n",
    "        elif amount:\n",
    "            if amount == \"all\":\n",
    "                amount = self.current_balance\n",
    "            self.buy_instrument(bar, amount = amount) # go long\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        nav = self.get_current_nav(bar)\n",
    "        self.add_position(date, price, 1, nav)\n",
    "\n",
    "    # helper method\n",
    "    def go_short(self, bar, units = None, amount = None):\n",
    "        if self.position == 1:\n",
    "            self.sell_instrument(bar, units = self.units) # if long position, go neutral first\n",
    "        if units:\n",
    "            self.sell_instrument(bar, units = units)\n",
    "        elif amount:\n",
    "            if amount == \"all\":\n",
    "                amount = self.current_balance\n",
    "            self.sell_instrument(bar, amount = amount) # go short\n",
    "        date, price, prediction = self.get_values(bar)\n",
    "        nav = self.get_current_nav(bar)\n",
    "        self.add_position(date, price, -1, nav)\n",
    "\n",
    "    def test_sma_strategy(self, SMA_S, SMA_L):\n",
    "        \n",
    "        # nice printout\n",
    "        stm = \"Testing SMA strategy | {} | SMA_S = {} & SMA_L = {}\".format(self.symbol, SMA_S, SMA_L)\n",
    "        print(\"-\" * 75)\n",
    "        print(stm)\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        # reset \n",
    "        self.position = 0  # initial neutral position\n",
    "        self.trades = 0  # no trades yet\n",
    "        self.current_balance = self.initial_balance  # reset initial capital\n",
    "        self.get_data() # reset dataset\n",
    "        \n",
    "        # prepare data\n",
    "        self.data[\"SMA_S\"] = self.data[\"price\"].rolling(SMA_S).mean()\n",
    "        self.data[\"SMA_L\"] = self.data[\"price\"].rolling(SMA_L).mean()\n",
    "        self.data.dropna(inplace = True)\n",
    "\n",
    "        # sma crossover strategy\n",
    "        for bar in range(len(self.data)-1): # all bars (except the last bar)\n",
    "            if self.data[\"SMA_S\"].iloc[bar] > self.data[\"SMA_L\"].iloc[bar]: # signal to go long\n",
    "                if self.position in [0, -1]:\n",
    "                    self.go_long(bar, amount = \"all\") # go long with full amount\n",
    "                    self.position = 1  # long position\n",
    "                    #self.trades +=1\n",
    "            elif self.data[\"SMA_S\"].iloc[bar] < self.data[\"SMA_L\"].iloc[bar]: # signal to go short\n",
    "                if self.position in [0, 1]:\n",
    "                    self.go_short(bar, amount = \"all\") # go short with full amount\n",
    "                    self.position = -1 # short position\n",
    "                    #self.trades +=1\n",
    "        self.close_pos(bar+1) # close position at the last bar\n",
    "        \n",
    "\n",
    "    def test_my_strategy(self):\n",
    "        \n",
    "        # nice printout\n",
    "        ma = \"Testing Special Strategy on | {} \".format(self.symbol)\n",
    "        print(\"-\" * 75)\n",
    "        print(ma)\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        # reset \n",
    "        self.position = 0  # initial neutral position\n",
    "        self.trades = 0  # no trades yet\n",
    "        self.current_balance = self.initial_balance  # reset initial capital\n",
    "        self.get_data() # reset dataset\n",
    "        \n",
    "        # my strategy\n",
    "        for bar in range(len(self.data)-1): # all bars (except the last bar)\n",
    "            print(\"*\" * 75)\n",
    "            self.print_current_nav(bar)\n",
    "            if self.data[\"pred\"].iloc[bar+1] > self.data[\"price\"].iloc[bar]: # signal to go long\n",
    "                if self.position in [0, -1]:\n",
    "                    self.go_long(bar, amount = \"all\") # go long with full amount\n",
    "                    self.position = 1  # long position\n",
    "                    self.print_current_position_value(bar)\n",
    "                    #self.trades +=1\n",
    "            elif self.data[\"pred\"].iloc[bar+1] < self.data[\"price\"].iloc[bar]: # signal to go short\n",
    "                if self.position in [0, 1]:\n",
    "                    self.go_short(bar, amount = \"all\") # go short with full amount\n",
    "                    self.position = -1 # short position\n",
    "                    self.print_current_position_value(bar)\n",
    "                    #self.trades +=1\n",
    "        self.close_pos(bar+1) # close position at the last bar\n",
    "        #self.positions[\"returns\"] = positions.current_balance - positions.current_balance.shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b88fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"CIupMS6t9JcsjSHYw7d3SRM2AJnQ0ZDCYRDShaIegkpPVT89b8eHD0lXlIzqW69v\"\n",
    "SECRET_KEY = \"pNfTuC0nWoB3fKCQNzIIbrmPpKqmP4rOzBm2OHrvItp3DFmmLSX8N2QT5YDSatcq\"\n",
    "client = Client(API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd672322",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'BTCUSDT'\n",
    "def get_data(symbol):\n",
    "    frame = pd.DataFrame(client.get_historical_klines(symbol, '1h', '3 months UTC'))\n",
    "    #frame = frame.iloc[:,0:4]\n",
    "    frame = frame.iloc[:,0:6]\n",
    "    frame.columns = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    #frame.set_index('Time', inplace=True)\n",
    "    #frame.index = pd.to_datetime(frame.index, unit='ms')\n",
    "    #frame = frame.astype(float)\n",
    "    #frame = frame[4].div(1000).to_frame('col')\n",
    "    return frame\n",
    "frame = get_data(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc52caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_data(symbol)\n",
    "frame.to_csv('/home/oguz/Desktop/project/file2.csv', float_format='%.6f', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3656b5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 11035 into shape (2207,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_test, final_y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpecnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mpecnet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#construction of input arrays\u001b[39;00m\n\u001b[1;32m     37\u001b[0m input_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(input_data)\n\u001b[0;32m---> 38\u001b[0m input_data\u001b[38;5;241m=\u001b[39m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m input_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(input_data)\n\u001b[1;32m     40\u001b[0m input_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(input_data)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 11035 into shape (2207,)"
     ]
    }
   ],
   "source": [
    "y_test, final_y_test = pecnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ace78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = IterativeBacktest(\"ISBANK\", \"2022-03-09\", \"2022-07-07\", 10000, use_prediction = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa50408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bc.test_my_strategy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
