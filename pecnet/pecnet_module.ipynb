{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, FinalModel\n",
      "File \u001b[0;32m~/Desktop/pecnet/models/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFinalModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/pecnet/models/Model.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf_kr\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBaseModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pecnet as pc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import Model, FinalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import random\n",
    "#This is for getting the same results. \n",
    "def reset_random_seeds(seed):\n",
    "   os.environ['PYTHONHASHSEED']=str(seed)\n",
    "   tf.random.set_seed(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "reset_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('close_is.csv').to_numpy().flatten()\n",
    "\n",
    "WINDOW_SIZE = 4\n",
    "SPLIT_INDEX = 3546 #3538 - 66 split, like Ajla's work\n",
    "#We are starting from 4 because we are constructing a rolling mean window from the same dataset. We want to align the split indexes for every network. \n",
    "ROLLING_WINDOW_SIZE = 5\n",
    "START = ROLLING_WINDOW_SIZE - 1\n",
    "ERROR_WINDOW_SIZE = 4\n",
    "\n",
    "\n",
    "#Average\n",
    "roll = pc.rolling_mean(input_data, ROLLING_WINDOW_SIZE) #yy5\n",
    "X_train, X_test, y_train, y_test, mean = pc.prepare_and_split_data(roll, WINDOW_SIZE, SPLIT_INDEX, start=START)\n",
    "\n",
    "#Succesive\n",
    "X_train_2, X_test_2, y_train_2, y_test_2, mean_2 = pc.prepare_and_split_data(input_data, WINDOW_SIZE, SPLIT_INDEX, start=START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using raw values for y. Not the average ones.\n",
    "#Also we will use mean of windowized input_data to denormalize\n",
    "y_test = y_test_2\n",
    "y_train = y_train_2\n",
    "mean = mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = Model(X_train.shape, y_train.shape)\n",
    "first_model.set_model_info(\"First Model\")\n",
    "first_model.set_fit_args()\n",
    "first_model.init_model()\n",
    "# first_model.model.summary()\n",
    "hist = first_model.fit_model(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for first model\n",
    "predict_train = first_model.model.predict(X_train).flatten()\n",
    "predict_test = first_model.model.predict(X_test).flatten()\n",
    "\n",
    "#Calculate First Model's errors\n",
    "error_train = predict_train - y_train\n",
    "error_test = predict_test - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix\n",
    "np.corrcoef(error_train, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second model, use error of the first one\n",
    "second_model = Model(X_train_2.shape, error_train.shape)\n",
    "second_model.set_model_info(\"Second Model\")\n",
    "second_model.set_fit_args()\n",
    "second_model.init_model()\n",
    "# second_model.model.summary()\n",
    "hist_2 = second_model.fit_model(X_train_2, error_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for second model\n",
    "predict_train_2 = second_model.model.predict(X_train_2).flatten()\n",
    "predict_test_2 = second_model.model.predict(X_test_2).flatten()\n",
    "#Calculate compensated errors\n",
    "error_train_compensated = (predict_train + mean[:X_train.shape[0]]) - predict_train_2\n",
    "error_test_compensated = (predict_test + mean[X_train.shape[0]:]) - predict_test_2\n",
    "#Calculate error for second model.\n",
    "error_train_2 = error_train_compensated - (y_train + mean[:X_train.shape[0]])\n",
    "error_test_2 = error_test_compensated - (y_test + mean[X_train.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge errors to create an error timeseries. \n",
    "error_all = np.concatenate([[0,0,0,0],error_train_2, error_test_2])\n",
    "#This is for aligning error data and other data.\n",
    "#Set this one to zero if you are adding zero padding to error_all. If not, make it same as ERROR_WINDOW_SIZE\n",
    "ERROR_ALIGNMENT = 0\n",
    "\n",
    "#For dividing errors from the same index.\n",
    "ERROR_SPLIT_INDEX = SPLIT_INDEX - ERROR_ALIGNMENT - START\n",
    "\n",
    "#Divide from the same point. \n",
    "X_train_error, X_test_error, y_train_error, y_test_error, mean_error = pc.prepare_and_split_error_data(error_all, ERROR_WINDOW_SIZE, ERROR_SPLIT_INDEX, normalize=True, fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third model, Error network\n",
    "error_model = Model(X_train_error.shape, y_train_error.shape)\n",
    "error_model.set_model_info(\"Error Model\")\n",
    "error_model.set_fit_args()\n",
    "error_model.init_model()\n",
    "# error_model.model.summary()\n",
    "hist_3 = error_model.fit_model(X_train_error, y_train_error, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for error Model\n",
    "predict_train_3 = error_model.model.predict(X_train_error).flatten()\n",
    "predict_test_3 = error_model.model.predict(X_test_error).flatten()\n",
    "\n",
    "#Calculate compensated errors.\n",
    "error_train_compensated_2 = error_train_compensated[ERROR_ALIGNMENT:] - (predict_train_3 + mean_error[:X_train_error.shape[0]])\n",
    "error_test_compensated_2 = error_test_compensated - (predict_test_3 + mean_error[X_train_error.shape[0]:])\n",
    "\n",
    "#Calculate error for error model.\n",
    "error_train_3 = (predict_train_3 + mean_error[:X_train_error.shape[0]])\n",
    "error_test_3 = (predict_test_3 + mean_error[X_train_error.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Final Network IO\n",
    "X_train_final = np.column_stack((predict_train[ERROR_ALIGNMENT:], predict_train_2[ERROR_ALIGNMENT:], error_train_3)) \n",
    "X_test_final = np.column_stack((predict_test, predict_test_2, error_test_3))\n",
    "\n",
    "y_train_final = y_train[ERROR_ALIGNMENT:]\n",
    "y_test_final = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model\n",
    "final_model = FinalModel(X_train_final.shape, y_train_final.shape)\n",
    "final_model.set_model_info(\"Final Model\")\n",
    "final_model.set_fit_args()\n",
    "final_model.init_model()\n",
    "# final_model.model.summary()\n",
    "hist_final = final_model.fit_model(X_train_final, y_train_final, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the values\n",
    "predict_train_final = final_model.predict(X_train_final).flatten()\n",
    "predict_test_final = final_model.predict(X_test_final).flatten()\n",
    "#Add mean\n",
    "predict_train_final = predict_train_final + mean_2[ERROR_ALIGNMENT:X_train.shape[0]]\n",
    "predict_test_final = predict_test_final + mean_2[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0,ax1),(ax2,ax3)) = plt.subplots(2,2, figsize=(10,10))\n",
    "ax0.plot(hist.history[\"loss\"])\n",
    "ax0.set_title(\"First Network (X=Average)\")\n",
    "\n",
    "ax1.plot(hist_2.history[\"loss\"])\n",
    "ax1.set_title(\"Second Network (X=Raw)\")\n",
    "\n",
    "ax2.plot(hist_3.history[\"loss\"])\n",
    "ax2.set_title(\"Error Network\")\n",
    "\n",
    "ax3.plot(hist_final.history[\"loss\"])\n",
    "ax3.set_title(\"Final Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot((y_test_2 + mean[y_train_2.shape[0]:])[:-1], c='b', label=\"Real\")\n",
    "plt.plot(predict_test_final[:-1], c='r', label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error((y_test_2 + mean[y_train_2.shape[0]:])[:-1], predict_test_final[:-1], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_final[-1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d8951838d5117fcbb66acd20a3271b2de0c7f82d5e92a0ba87e59707f806a06"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
